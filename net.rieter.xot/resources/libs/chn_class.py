# coding=utf-8
#==============================================================================
# LICENSE Retrospect-Framework - CC BY-NC-ND
#===============================================================================
# This work is licenced under the Creative Commons
# Attribution-Non-Commercial-No Derivative Works 3.0 Unported License. To view a
# copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/3.0/
# or send a letter to Creative Commons, 171 Second Street, Suite 300,
# San Francisco, California 94105, USA.
#===============================================================================

import urlparse
from datetime import datetime

import mediaitem
from locker import LockWithDialog

from regexer import Regexer
from cloaker import Cloaker
from xbmcwrapper import XbmcWrapper, XbmcDialogProgressWrapper
from config import Config
from initializer import Initializer
from logger import Logger
from urihandler import UriHandler
from parserdata import ParserData
from textures import TextureHandler

from helpers.stopwatch import StopWatch
from helpers.htmlentityhelper import HtmlEntityHelper
from helpers.encodinghelper import EncodingHelper
from helpers.jsonhelper import JsonHelper
from helpers.languagehelper import LanguageHelper
from helpers.statistics import Statistics
from addonsettings import AddonSettings, LOCAL


class Channel:
    """
    main class from which all channels inherit
    """

    def __init__(self, channelInfo):
        """Initialisation of the class.

        Arguments:
        channelInfo: ChannelInfo - The channel info object to base this channel on.

        All class variables should be instantiated here and this method should not
        be overridden by any derived classes.

        """

        Logger.Info("Initializing channel (__init__): %s", channelInfo)

        self.mainListItems = []
        self.parentItem = None

        # The proxy to be used for this channel
        self.proxy = AddonSettings.GetProxyForChannel(channelInfo)
        self.localIP = AddonSettings.GetLocalIPHeaderForChannel(channelInfo)

        # More and more API's need a specific set of headers. This set is used for the self.mainListUri, and is set to
        # all items generated by the chn_class.py.
        self.httpHeaders = dict()
        self.loggedOn = False

        # Initialize channel stuff from ChannelInfo object
        self.guid = channelInfo.guid
        self.id = channelInfo.id

        self.channelName = channelInfo.channelName
        self.safeName = channelInfo.safeName
        self.channelCode = channelInfo.channelCode
        self.channelDescription = channelInfo.channelDescription
        self.moduleName = channelInfo.moduleName
        self.compatiblePlatforms = channelInfo.compatiblePlatforms
        self.sortOrder = channelInfo.sortOrder
        self.category = channelInfo.category
        self.language = channelInfo.language
        self.path = channelInfo.path
        self.version = channelInfo.version

        # get the textures from the channelinfo and get their full uri's.
        self.icon = TextureHandler.Instance().GetTextureUri(self, channelInfo.icon)
        self.fanart = TextureHandler.Instance().GetTextureUri(self, channelInfo.fanart)

        # ============== Actual channel setup STARTS here and should be overwritten from derived classes ===============
        self.noImage = ""

        # set context menu items
        self.contextMenuItems = []

        # configure login stuff
        self.requiresLogon = False

        # setup the urls
        self.mainListUri = ""
        self.baseUrl = ""
        self.swfUrl = ""

        # setup the main parsing data
        # self.dataHandlers = dict()
        # self.updateHandlers = dict()
        self.dataParsers = dict()

        self.episodeItemRegex = ''      # : used for the ParseMainList
        self.episodeItemJson = None     # : used for the ParseMainList
        self.videoItemRegex = ''        # : used for the ParseMainList
        self.videoItemJson = None       # : used for the ParseMainList
        self.folderItemRegex = ''       # : used for the CreateFolderItem
        self.folderItemJson = None      # : used for the CreateFolderItem
        self.mediaUrlRegex = ''         # : used for the UpdateVideoItem
        self.mediaUrlJson = None        # : used for the UpdateVideoItem

        """
            The ProcessPageNavigation method will parse the current data using the pageNavigationRegex. It will
            create a pageItem using the CreatePageItem method. If no CreatePageItem method is in the channel,
            a default one will be created with the number present in the resultset location specified in the
            pageNavigationRegexIndex and the url from the combined resultset. If that url does not contain http://
            the self.baseUrl will be added.
        """
        self.pageNavigationIndicationRegex = ''
        self.pageNavigationRegex = ''
        self.pageNavigationJson = None
        self.pageNavigationRegexIndex = 0
        self.pageNavigationJsonIndex = None

        #===============================================================================================================
        # non standard items

        #===============================================================================================================
        # Test cases:

        # ====================================== Actual channel setup STOPS here =======================================
        return

    def InitChannel(self):
        """Initializes the channel and will call some post processing stuff.

        This method is called for each add-on call and can be used to do some
        channel initialisation.

        """

        Logger.Debug("Initializing channel (InitChannel): %s", self)

        # Make sure all images are from the correct absolute location
        # self.icon = self.GetImageLocation(self.icon) -> already in the __init__
        # self.fanart = self.GetImageLocation(self.fanart) -> already in the __init__
        self.noImage = TextureHandler.Instance().GetTextureUri(self, self.noImage)
        return

    #noinspection PyUnusedLocal
    def CtMnSettings(self, item):  # @UnusedVariable
        """Shows the Addon settings

        Arguments:
        item : MediaItem - the currently selected item

        The <item> argument is not really used here, but is just here for compatibility
        in showing the contextmenu.

        """

        AddonSettings.ShowSettings()
        pass

    def CtMnRefresh(self, item):
        """ refreshes an item's MediaParts

        Arguments:
        item : MediaItem - the items to refresh.

        CAUTION: only use this method if the UpdateVideoItem fetches the MediaParts

        """

        # reset the media item parts, as they will be reloaded.
        if item.HasMediaItemParts():
            item.MediaItemParts = []

        return self.ProcessVideoItem(item)

    def ProcessFolderList(self, item=None):
        """Process the selected item and get's it's child items using the available dataparsers.

        Arguments:
        item : [opt] MediaItem - the selected item

        Returns:
        A list of MediaItems that form the childeren of the <item>.

        Accepts an <item> and returns a list of MediaListems with at least name & url
        set. The following actions are done:

        * determining the correct parsers to use
        * call a pre-processor
        * parsing the data with the parsers
        * calling the creators for item creations

        if the item is NOne, we assume that we are dealing with the first call for this channel and the mainlist uri
        is used.

        """

        items = []
        self.parentItem = item

        if item is None:
            Logger.Info("ProcessFolderList :: No item was specified. Assuming it was the main channel list")
            url = self.mainListUri
        elif len(item.items) > 0:
            return item.items
        else:
            url = item.url

        # Determine the handlers and process
        dataParsers = self.__GetDataParsers(url)
        # Exclude the updaters only
        dataParsers = filter(lambda p: not p.IsVideoUpdaterOnly(), dataParsers)
        if filter(lambda p: p.LogOnRequired, dataParsers):
            Logger.Info("One or more dataparsers require logging in.")
            self.loggedOn = self.LogOn()

        # now set the headers here and not earlier in case they might have been update by the logon
        if item is not None and item.HttpHeaders:
            headers = item.HttpHeaders
        else:
            headers = self.httpHeaders

        # Let's retrieve the required data. Main url's
        if url.startswith("http:") or url.startswith("https:") or url.startswith("file:"):
            # Disable cache on live folders
            noCache = item is not None and not item.IsPlayable() and item.isLive
            if noCache:
                Logger.Debug("Disabling cache for '%s'", item)
            data = UriHandler.Open(url, proxy=self.proxy, additionalHeaders=headers, noCache=noCache)
        # Searching a site using SearchSite()
        elif url == "searchSite" or url == "#searchSite":
            Logger.Debug("Starting to search")
            return self.SearchSite()
        # Labels instead of url's
        elif url.startswith("#"):
            data = ""
        # Others
        else:
            Logger.Debug("Unknown URL format. Setting data to ''")
            data = ""

        # first check if there is a generic pre-processor
        preProcs = filter(lambda p: p.IsGenericPreProcessor(), dataParsers)
        numPreProcs = len(preProcs)
        Logger.Trace("Processing %s Generic Pre-Processors DataParsers", numPreProcs)
        if numPreProcs > 1:
            # warn for strange results if more than 1 generic pre-processor is present.
            Logger.Warning("More than one Generic Pre-Processor is found (%s). They are being processed in the "
                           "order that Python likes which might result in unexpected result.", numPreProcs)

        for dataParser in preProcs:
            # remove it from the list
            dataParsers.remove(dataParser)

            # and process it
            Logger.Debug("Processing %s", dataParser)
            (data, preItems) = dataParser.PreProcessor(data)
            items += preItems

            if isinstance(data, JsonHelper):
                Logger.Debug("Generic preprocessor resulted in JsonHelper data")

        # The the other handlers
        Logger.Trace("Processing %s Normal DataParsers", len(dataParsers))
        handlerJson = None
        for dataParser in dataParsers:
            Logger.Debug("Processing %s", dataParser)

            # Check for preprocessors
            if dataParser.PreProcessor:
                Logger.Debug("Processing DataParser.PreProcessor")
                (handlerData, preItems) = dataParser.PreProcessor(data)
                items += preItems
            else:
                handlerData = data

            Logger.Debug("Processing DataParser.Parser")
            if dataParser.Parser is None or (dataParser.Parser == "" and not dataParser.IsJson):
                if dataParser.Creator:
                    Logger.Warning("No <parser> found for %s. Skipping.", dataParser.Creator)
                continue

            if dataParser.IsJson:
                if handlerJson is None:
                    # Cache the json requests to improve performance
                    Logger.Trace("Caching JSON results for Dataparsing")
                    if isinstance(handlerData, JsonHelper):
                        handlerJson = handlerData
                    else:
                        handlerJson = JsonHelper(handlerData, Logger.Instance())

                Logger.Trace(dataParser.Parser)
                parserResults = handlerJson.GetValue(fallback=[], *dataParser.Parser)

                if not isinstance(parserResults, (tuple, list)):
                    # if there is just one match, return that as a list
                    parserResults = [parserResults]
            else:
                if isinstance(handlerData, JsonHelper):
                    raise ValueError("Cannot perform Regex Parser on JsonHelper.")
                else:
                    parserResults = Regexer.DoRegex(dataParser.Parser, handlerData)

            Logger.Debug("Processing DataParser.Creator for %s items", len(parserResults))
            for parserResult in parserResults:
                handlerResult = dataParser.Creator(parserResult)
                if handlerResult is not None:
                    if isinstance(handlerResult, list):
                        items += handlerResult
                    else:
                        items.append(handlerResult)

        # should we exclude DRM/GEO?
        hideGeoLocked = AddonSettings.HideGeoLockedItemsForLocation(self.language)
        hideDrmProtected = AddonSettings.HideDrmItems()
        hidePremium = AddonSettings.HidePremiumItems()
        hideFolders = AddonSettings.HideRestrictedFolders()
        typeToExclude = None
        if not hideFolders:
            typeToExclude = "folder"

        oldCount = len(items)
        if hideDrmProtected:
            Logger.Debug("Hiding DRM items")
            items = filter(lambda i: not i.isDrmProtected or i.type == typeToExclude, items)
        if hideGeoLocked:
            Logger.Debug("Hiding GEO Locked items due to GEO region: %s", self.language)
            items = filter(lambda i: not i.isGeoLocked or i.type == typeToExclude, items)
        if hidePremium:
            Logger.Debug("Hiding Premium items")
            items = filter(lambda i: not i.isPaid or i.type == typeToExclude, items)
            # items = filter(lambda i: not i.isPaid or i.type == "folder", items)

        cloaker = Cloaker(self, AddonSettings.store(LOCAL), logger=Logger.Instance())
        if not AddonSettings.ShowCloakedItems():
            Logger.Debug("Hiding Cloaked items")
            items = filter(lambda i: not cloaker.IsCloaked(i.url), items)
        else:
            cloakedItems = filter(lambda i: cloaker.IsCloaked(i.url), items)
            for c in cloakedItems:
                c.isCloaked = True

        if len(items) != oldCount:
            Logger.Info("Hidden %s items due to DRM/GEO/Premium/Cloak filter (Hide Folders=%s)",
                        oldCount - len(items), hideFolders)

        # Check for grouping or not
        limit = AddonSettings.GetListLimit()
        folderItems = filter(lambda x: x.type.lower() == "folder", items)

        # we should also de-duplicate before calculating
        folderItems = list(set(folderItems))
        folders = len(folderItems)

        if 0 < limit < folders:
            # let's filter them by alphabet if the number is exceeded
            Logger.Debug("Creating Groups for list exceeding '%s' folder items. Total folders found '%s'.",
                         limit, folders)
            other = LanguageHelper.GetLocalizedString(LanguageHelper.OtherChars)
            titleFormat = LanguageHelper.GetLocalizedString(LanguageHelper.StartWith)
            result = dict()
            nonGrouped = []
            # prefixes = ("de", "het", "the", "een", "a", "an")

            for subItem in items:
                if subItem.dontGroup or subItem.type != "folder":
                    nonGrouped.append(subItem)
                    continue

                char = subItem.name[0].upper()
                # Should we de-prefix?
                # for p in prefixes:
                #     if subItem.name.lower().startswith(p + " "):
                #         char = subItem.name[len(p) + 1][0].upper()

                if char.isdigit():
                    char = "0-9"
                elif not char.isalpha():
                    char = other

                if char not in result:
                    Logger.Trace("Creating Grouped item from: %s", subItem)
                    if char == other:
                        item = mediaitem.MediaItem(titleFormat.replace("'", "") % (char,), "")
                    else:
                        item = mediaitem.MediaItem(titleFormat % (char.upper(),), "")
                    item.thumb = self.noImage
                    item.complete = True
                    # item.SetDate(2100 + ord(char[0]), 1, 1, text='')
                    result[char] = item
                else:
                    item = result[char]
                item.items.append(subItem)

            items = nonGrouped + result.values()

        Logger.Trace("Found '%s' items", len(items))
        return list(set(items))

    def ProcessVideoItem(self, item):
        """ Process a video item using the required dataparsers

        @param item:    The Item to update
        @return:        An updated item.

        """

        dataParsers = self.__GetDataParsers(item.url)
        if not dataParsers:
            Logger.Error("No dataparsers found cannot update item.")
            return item

        dataParsers = filter(lambda d: d.Updater is not None, dataParsers)
        if len(dataParsers) < 1:
            Logger.Warning("No DataParsers with Updaters found.")
            return item

        if len(dataParsers) > 1:
            Logger.Warning("More than 2 DataParsers with Updaters found. Only using first one.")
        dataParser = dataParsers[0]

        if not dataParser.Updater:
            Logger.Error("No videoupdater found cannot update item.")
            return item

        if dataParser.LogOnRequired:
            Logger.Info("One or more dataparsers require logging in.")
            self.loggedOn = self.LogOn()

        Logger.Debug("Processing Updater from %s", dataParser)
        return dataParser.Updater(item)

    def ParseMainList(self, returnData=False):
        """Parses the mainlist of the channel and returns a list of MediaItems

        This method creates a list of MediaItems that represent all the different
        programs that are available in the online source. The list is used to fill
        the ProgWindow.

        Keyword parameters:
        returnData : [opt] boolean - If set to true, it will return the retrieved
                                     data as well

        Returns a list of MediaItems that were retrieved.

        """

        items = []
        if len(self.mainListItems) > 1:
            if returnData:
                return self.mainListItems, ""
            else:
                return self.mainListItems

        data = UriHandler.Open(self.mainListUri, proxy=self.proxy, additionalHeaders=self.httpHeaders)
        Logger.Trace("Retrieved %s chars as mainlist data", len(data))

        # first process folder items.
        watch = StopWatch('Mainlist', Logger.Instance())

        episodeItems = []
        if not self.episodeItemRegex == "" and self.episodeItemRegex is not None:
            Logger.Trace("Using Regexer for episodes")
            episodeItems = Regexer.DoRegex(self.episodeItemRegex, data)
            watch.Lap("Mainlist Regex complete")

        elif self.episodeItemJson is not None:
            Logger.Trace("Using JsonHelper for episodes")
            json = JsonHelper(data, Logger.Instance())
            episodeItems = json.GetValue(*self.episodeItemJson)
            watch.Lap("Mainlist Json complete")

        Logger.Debug('Starting CreateEpisodeItem for %s items', len(episodeItems))
        for episodeItem in episodeItems:
            Logger.Trace('Starting CreateEpisodeItem for %s', self.channelName)
            tmpItem = self.CreateEpisodeItem(episodeItem)
            # catch the return of None
            if tmpItem:
                items.append(tmpItem)

        # Filter out the duplicates using the HASH power of a set
        items = list(set(items))

        watch.Lap("MediaItem creation complete")
        self.mainListItems = items

        if returnData:
            return items, data
        else:
            return items

    def SearchSite(self, url=None):
        """Creates an list of items by searching the site

        Keyword Arguments:
        url : String - Url to use to search with a %s for the search parameters

        Returns:
        A list of MediaItems that should be displayed.

        This method is called when the URL of an item is "searchSite". The channel
        calling this should implement the search functionality. This could also include
        showing of an input keyboard and following actions.

        The %s the url will be replaced with an URL encoded representation of the
        text to search for.

        """

        items = []
        if url is None:
            item = mediaitem.MediaItem("Search Not Implented", "", type='video')
            item.icon = self.icon
            items.append(item)
        else:
            items = []
            needle = XbmcWrapper.ShowKeyBoard()
            if needle:
                Logger.Debug("Searching for '%s'", needle)
                # convert to HTML
                needle = HtmlEntityHelper.UrlEncode(needle)
                searchUrl = url % (needle, )
                temp = mediaitem.MediaItem("Search", searchUrl)
                return self.ProcessFolderList(temp)

        return items

    def CreateEpisodeItem(self, resultSet):
        """Creates a new MediaItem for an episode

        Arguments:
        resultSet : list[string] - the resultSet of the self.episodeItemRegex

        Returns:
        A new MediaItem of type 'folder'

        This method creates a new MediaItem from the Regular Expression or Json
        results <resultSet>. The method should be implemented by derived classes
        and are specific to the channel.

        """

        Logger.Trace(resultSet)

        # Validate the input and raise errors
        if not isinstance(resultSet, dict):
            Logger.Critical("No Dictionary as a resultSet. Implement a custom CreateEpisodeItem")
            raise NotImplementedError("No Dictionary as a resultSet. Implement a custom CreateEpisodeItem")
            # return None
        elif "title" not in resultSet or "url" not in resultSet:
            Logger.Warning("No ?P<title> or ?P<url> in resultSet")
            raise LookupError("No ?P<title> or ?P<url> in resultSet")
            # return None

        # the URL
        url = resultSet["url"]
        if not url.startswith("http"):
            url = "%s/%s" % (self.baseUrl.rstrip('/'), url.lstrip('/'))

        # the title
        title = resultSet["title"]
        if title.isupper():
            title = title.title()

        item = mediaitem.MediaItem(title, url)
        item.thumb = resultSet.get("thumburl", None)
        item.description = resultSet.get("description", "")
        item.icon = self.icon
        item.complete = True
        item.fanart = self.fanart
        item.HttpHeaders = self.httpHeaders
        return item

    def PreProcessFolderList(self, data):
        """Performs pre-process actions for data processing

        Arguments:
        data : string - the retrieve data that was loaded for the current item and URL.

        Returns:
        A tuple of the data and a list of MediaItems that were generated.


        Accepts an data from the ProcessFolderList method, BEFORE the items are
        processed. Allows setting of parameters (like title etc) for the channel.
        Inside this method the <data> could be changed and additional items can
        be created.

        The return values should always be instantiated in at least ("", []).

        """

        Logger.Info("Performing Pre-Processing")
        items = []
        Logger.Debug("Pre-Processing finished")
        return data, items

    # def ProcessPageNavigation(self, data):
    #     """Generates a list of pageNavigation items.
    #
    #     Arguments:
    #     data : string - the retrieve data that was loaded for the current item and URL.
    #
    #     Returns:
    #     A list of MediaItems of type 'page'
    #
    #     Parses the <data> using the self.pageNavigationRegex and then calls the
    #     self.CreatePageItem method for each result to create a page item. The
    #     list of those items is returned.
    #
    #     """
    #
    #     Logger.Debug("Starting ProcessPageNavigation")
    #
    #     pageItems = []
    #     pages = []
    #
    #     # try the regex on the current data
    #     if not self.pageNavigationRegex == "" and not self.pageNavigationRegex is None:
    #         pages = Regexer.DoRegex(self.pageNavigationRegex, data)
    #
    #     elif not self.pageNavigationJson is None:
    #         pageJson = JsonHelper(data, logger=Logger.Instance())
    #         pages = pageJson.GetValue(*self.pageNavigationJson)
    #
    #         if pages is None:
    #             # no matches, so no pages
    #             pages = []
    #         elif not isinstance(pages, (tuple, list)):
    #             # if there is just one match, return that as a list
    #             pages = [pages]
    #
    #     if len(pages) == 0:
    #         Logger.Debug("No pages found.")
    #         return pageItems
    #
    #     Logger.Debug('Starting CreatePageItem for %s items', len(pages))
    #     for page in pages:
    #         Logger.Trace('Starting CreatePageItem for %s', self.channelName)
    #         item = self.CreatePageItem(page)
    #         if not item is None:
    #             pageItems.append(item)
    #
    #     # Filter out the duplicates using the HASH power of a set
    #     pageItems = list(set(pageItems))
    #
    #     # Logger.Debug(pageItems)
    #     return pageItems

    def CreatePageItem(self, resultSet):
        """Creates a MediaItem of type 'page' using the resultSet from the regex.

        Arguments:
        resultSet : tuple(string) - the resultSet of the self.pageNavigationRegex

        Returns:
        A new MediaItem of type 'page'

        This method creates a new MediaItem from the Regular Expression or Json
        results <resultSet>. The method should be implemented by derived classes
        and are specific to the channel.

        """

        Logger.Debug("Starting CreatePageItem")
        total = ''

        for result in resultSet:
            total = "%s%s" % (total, result)

        total = HtmlEntityHelper.StripAmp(total)

        if not self.pageNavigationRegexIndex == '':
            item = mediaitem.MediaItem(resultSet[self.pageNavigationRegexIndex], urlparse.urljoin(self.baseUrl, total))
        else:
            item = mediaitem.MediaItem("0", "")

        item.type = "page"
        item.fanart = self.fanart
        item.HttpHeaders = self.httpHeaders

        Logger.Debug("Created '%s' for url %s", item.name, item.url)
        return item

    def CreateFolderItem(self, resultSet):
        """Creates a MediaItem of type 'folder' using the resultSet from the regex.

        Arguments:
        resultSet : tuple(strig) - the resultSet of the self.folderItemRegex

        Returns:
        A new MediaItem of type 'folder'

        This method creates a new MediaItem from the Regular Expression or Json
        results <resultSet>. The method should be implemented by derived classes
        and are specific to the channel.

        """

        Logger.Trace(resultSet)

        # Validate the input and raise errors
        if not isinstance(resultSet, dict):
            Logger.Critical("No Dictionary as a resultSet. Implement a custom CreateVideoItem")
            raise NotImplementedError("No Dictionary as a resultSet. Implement a custom CreateVideoItem")
            # return None
        elif "title" not in resultSet or "url" not in resultSet:
            Logger.Warning("No ?P<title> or ?P<url> in resultSet")
            raise LookupError("No ?P<title> or ?P<url> in resultSet")
            # return None

        # The URL
        url = resultSet["url"]
        if not url.startswith("http"):
            url = "%s/%s" % (self.baseUrl.rstrip('/'), url.lstrip('/'))

        # The title
        title = resultSet["title"]
        if title.isupper():
            title = title.title()

        item = mediaitem.MediaItem(title, url)
        item.description = resultSet.get("description", "")
        item.thumb = resultSet.get("thumburl", "")
        item.icon = self.icon
        item.type = 'folder'
        item.fanart = self.fanart
        item.HttpHeaders = self.httpHeaders
        item.complete = True
        return item

    def CreateVideoItem(self, resultSet):
        """Creates a MediaItem of type 'video' using the resultSet from the regex.

        Arguments:
        resultSet : tuple (string) - the resultSet of the self.videoItemRegex

        Returns:
        A new MediaItem of type 'video' or 'audio' (despite the method's name)

        This method creates a new MediaItem from the Regular Expression or Json
        results <resultSet>. The method should be implemented by derived classes
        and are specific to the channel.

        If the item is completely processed an no further data needs to be fetched
        the self.complete property should be set to True. If not set to True, the
        self.UpdateVideoItem method is called if the item is focussed or selected
        for playback.

        """

        Logger.Trace(resultSet)

        # Validate the input and raise errors
        if not isinstance(resultSet, dict):
            Logger.Critical("No Dictionary as a resultSet. Implement a custom CreateVideoItem")
            raise NotImplementedError("No Dictionary as a resultSet. Implement a custom CreateVideoItem")
            # return None
        elif "title" not in resultSet or "url" not in resultSet:
            Logger.Warning("No ?P<title> or ?P<url> in resultSet")
            raise LookupError("No ?P<title> or ?P<url> in resultSet")
            # return None

        # The URL
        url = resultSet["url"]
        if not url.startswith("http"):
            url = "%s/%s" % (self.baseUrl.rstrip('/'), url.lstrip('/'))

        # The title
        if "subtitle" in resultSet and resultSet["subtitle"] is not None:
            title = "%(title)s - %(subtitle)s" % resultSet
        else:
            title = resultSet["title"]
        if title.isupper():
            title = title.title()

        item = mediaitem.MediaItem(title, url)
        item.description = resultSet.get("description", "")
        item.thumb = resultSet.get("thumburl", "")
        item.icon = self.icon
        item.type = 'video'
        item.fanart = self.fanart
        item.HttpHeaders = self.httpHeaders
        item.complete = False
        return item

    def UpdateVideoItem(self, item):
        """Updates an existing MediaItem with more data.

        Arguments:
        item : MediaItem - the MediaItem that needs to be updated

        Returns:
        The original item with more data added to it's properties.

        Used to update none complete MediaItems (self.complete = False). This
        could include opening the item's URL to fetch more data and then process that
        data or retrieve it's real media-URL.

        The method should at least:
        * cache the thumbnail to disk (use self.noImage if no thumb is available).
        * set at least one MediaItemPart with a single MediaStream.
        * set self.complete = True.

        if the returned item does not have a MediaItemPart then the self.complete flag
        will automatically be set back to False.

        """

        Logger.Debug('Starting UpdateVideoItem for %s (%s)', item.name, self.channelName)

        data = UriHandler.Open(item.url, proxy=self.proxy, additionalHeaders=item.HttpHeaders)

        url = Regexer.DoRegex(self.mediaUrlRegex, data)[-1]
        part = mediaitem.MediaItemPart(item.name, url)
        item.MediaItemParts.append(part)

        Logger.Info('finishing UpdateVideoItem. MediaItems are %s', item)

        if not item.thumb and self.noImage:
            # no thumb was set yet and no url
            Logger.Debug("Setting thumb to %s", item.thumb)
            item.thumb = self.noImage

        if not item.HasMediaItemParts():
            item.complete = False
        else:
            item.complete = True
        return item

    def DownloadVideoItem(self, item):
        """Downloads an existing MediaItem with more data.

        Arguments:
        item : MediaItem - the MediaItem that should be downloaded.

        Returns:
        The original item with more data added to it's properties.

        Used to download an <item>. If the item is not complete, the self.UpdateVideoItem
        method is called to update the item. The method downloads only the MediaStream
        with the bitrate that was set in the addon settings.

        After downloading the self.downloaded property is set.

        """

        if not item.IsPlayable():
            Logger.Error("Cannot download a folder item.")
            return item

        if item.IsPlayable():
            if not item.complete:
                Logger.Info("Fetching MediaUrl for PlayableItem[%s]", item.type)
                item = self.ProcessVideoItem(item)

            if not item.complete or not item.HasMediaItemParts():
                Logger.Error("Cannot download incomplete item or item without MediaItemParts")
                return item

            i = 1
            bitrate = AddonSettings.GetMaxStreamBitrate(self)
            for mediaItemPart in item.MediaItemParts:
                Logger.Info("Trying to download %s", mediaItemPart)
                stream = mediaItemPart.GetMediaStreamForBitrate(bitrate)
                downloadUrl = stream.Url
                extension = UriHandler.GetExtensionFromUrl(downloadUrl)
                if len(item.MediaItemParts) > 1:
                    saveFileName = "%s-Part_%s.%s" % (item.name, i, extension)
                else:
                    saveFileName = "%s.%s" % (item.name, extension)
                Logger.Debug(saveFileName)

                # headers = item.HttpHeaders + mediaItemPart.HttpHeaders
                headers = item.HttpHeaders.copy()
                headers.update(mediaItemPart.HttpHeaders)

                progressDialog = XbmcDialogProgressWrapper("Downloading Item", item.name, stream.Url)
                folderName = XbmcWrapper.ShowFolderSelection('Select download destination for "%s"' % (saveFileName, ))
                UriHandler.Download(downloadUrl, saveFileName, folderName, progressDialog, proxy=self.proxy,
                                    additionalHeaders=headers)
                i += 1

            item.downloaded = True

        return item

    #noinspection PyUnusedLocal
    def LogOn(self):
        """Logs on to a website, using an url.

        Returns:
        True if successful.

        First checks if the channel requires log on. If so and it's not already
        logged on, it should handle the log on. That part should be implemented
        by the specific channel.

        More arguments can be passed on, but must be handled by custom code.

        After a successful log on the self.loggedOn property is set to True and
        True is returned.

        """

        if not self.requiresLogon:
            Logger.Debug("No login required of %s", self.channelName)
            return True

        if self.loggedOn:
            Logger.Info("Already logged in")
            return True

        return False

    def PlayVideoItem(self, item, bitrate=None):
        """Starts the playback of the <item> with the specific <bitrate> in the selected <player>.

        Arguments:
        item    : MediaItem - The item to start playing

        Keyword Arguments:
        bitrate : [opt] integer - The requested bitrate in Kbps or None.
        plugin  : [opt] boolean - Indication whether we are in plugin mode. If True, there
                                  will not actually be playback, rather a tuple with info.

        Returns:
        The updated <item>.

        Starts the playback of the selected MediaItem <item>. Before playback is started
        the item is check for completion (item.complete), if not completed, the self.UpdateVideoItem
        method is called to update the item.

        After updating the requested bitrate playlist is selected, if bitrate was set to None
        the bitrate is retrieved from the addon settings. The playlist is then played using the
        requested player.

        """

        if bitrate is None:
            # use the bitrate from the xbmc settings if bitrate was not specified and the item is MultiBitrate
            bitrate = AddonSettings.GetMaxStreamBitrate(self)

        # should we download items?
        Logger.Debug("Checking for not streamable parts")
        # We need to substract the download time from processing time
        downloadStart = datetime.now()
        for part in item.MediaItemParts:
            if not part.CanStream:
                stream = part.GetMediaStreamForBitrate(bitrate)
                if not stream.Downloaded:
                    Logger.Debug("Downloading not streamable part: %s\nDownloading Stream: %s", part, stream)

                    # we need a unique filename
                    fileName = EncodingHelper.EncodeMD5(stream.Url)
                    extension = UriHandler.GetExtensionFromUrl(stream.Url)

                    # now we force the busy dialog to close, else we cannot cancel the download
                    # setResolved will not work.
                    LockWithDialog.CloseBusyDialog()

                    # headers = item.HttpHeaders + part.HttpHeaders
                    headers = item.HttpHeaders.copy()
                    headers.update(part.HttpHeaders)

                    Logger.Error(headers)
                    streamFilename = "xot.%s.%skbps-%s.%s" % (fileName, stream.Bitrate, item.name, extension)
                    progressDialog = XbmcDialogProgressWrapper("Downloading Item", item.name, stream.Url)
                    cacheFile = UriHandler.Download(stream.Url, streamFilename, self.GetDefaultCachePath(),
                                                    progressDialog.ProgressUpdate, proxy=self.proxy,
                                                    additionalHeaders=headers)

                    if cacheFile == "":
                        Logger.Error("Cannot download stream %s \nFrom: %s", stream, part)
                        return

                    if cacheFile.startswith("\\\\"):
                        cacheFile = cacheFile.replace("\\", "/")
                        stream.Url = "file:///%s" % (cacheFile,)
                    else:
                        stream.Url = "file://%s" % (cacheFile,)
                        # stream.Url = cacheFile
                    stream.Downloaded = True

        # We need to substract the download time from processing time
        downloadTime = datetime.now() - downloadStart
        downloadDuration = 1000 * downloadTime.seconds + downloadTime.microseconds / 1000

        # Set item as downloaded
        item.downloaded = True

        # get the playlist
        (playList, srt) = item.GetXBMCPlayList(bitrate, updateItemUrls=True, proxy=self.proxy)

        # call for statistics with timing
        Statistics.RegisterPlayback(self, item, Initializer.StartTime, -downloadDuration)

        # if the item urls have been updated, don't start playback, but return
        return playList, srt

    def GetDefaultCachePath(self):
        """ returns the default cache path for this channel

        Could be overridden by a channel.

        """

        return Config.cacheDir

    def GetVerifiableVideoUrl(self, url):
        """Creates an RTMP(E) url that can be verified using an SWF URL.

        Arguments:
        url : string - the URL that should be made verifiable.

        Returns:
        A new URL that includes the self.swfUrl in the form of "url --swfVfy|-W swfUrl".
        If self.swfUrl == "", the original URL is returned.

        """

        if self.swfUrl == "":
            return url

        # Kodi 17.x also accepts an SWF-url as swfvfy option (https://www.ffmpeg.org/ffmpeg-protocols.html#rtmp).
        # This option should be set via the XbmcListItem.setProperty, so within Retrospect via:
        #   part.AddProperty("swfvfy", self.swfUrl)
        # Or as an URL parameter swfvfy where we add the full URL instead of just 1:
        #   return "%s swfvfy=%s" % (url, self.swfUrl)

        if AddonSettings.IsMinVersion(17):
            Logger.Debug("Using Kodi 17+ RTMP parameters")
            return "%s swfvfy=%s" % (url, self.swfUrl)
        else:
            Logger.Debug("Using Legacy (Kodi 16 and older) RTMP parameters")
            # return "%s swfurl=%s swfvfy=true" % (url, self.swfUrl)
            return "%s swfurl=%s swfvfy=1" % (url, self.swfUrl)

    def GetImageLocation(self, image):
        """returns the path for a specific image name.

        Arguments:
        image : string - the filename of the requested argument.

        Returns:
        The full local path to the requested image.

        """

        # if Config.CdnUrl is None:
        #     return os.path.join(os.path.dirname(sys.modules[self.__module__].__file__), image)
        # return "%s%s" % (Config.CdnUrl, image)

        return TextureHandler.Instance().GetTextureUri(self, image)

    def _AddDataParsers(self, urls, name=None, preprocessor=None,
                        parser=None, creator=None, updater=None,
                        json=False, matchType=ParserData.MatchStart):
        """ Adds a DataParser to the handlers dictionary for the  given urls

        @param urls:            The URLs that triggers these handlers
        @param preprocessor:    The pre-processor called
        @param parser:          The parser (regex or json)
        @param creator:         The creator called with the results from the parser
        @param updater:         The updater called for updating a item
        @param json:            Indication whether the parsers are JSON (True) or Regex (False)
        @param matchType:       The type of matching to use

        @return: Nothing

        """

        for url in urls:
            self._AddDataParser(url, name, preprocessor, parser, creator, updater, json, matchType=matchType)
        return

    def _GetSetting(self, settingId, valueForNone=None):
        """ Retrieves channel specific settings. Just to prevent us from importing AddonSettings in all channels.

        @param settingId: the channels specific setting
        @return: the settings value from the Add-on using the Kodi settings API

        """

        setting = AddonSettings.GetChannelSetting(self, settingId, valueForNone)
        return setting

    # noinspection PyPropertyAccess
    def _AddDataParser(self, url, name=None, preprocessor=None,
                       parser=None, creator=None, updater=None,
                       json=False, matchType=ParserData.MatchStart, requiresLogon=False):
        """ Adds a DataParser to the handlers dictionary

        @param url:             The URL that triggers these handlers
        @param preprocessor:    The pre-processor called
        @param parser:          The parser (regex or json)
        @param creator:         The creator called with the results from the parser
        @param updater:         The updater called for updating a item
        @param json:            Indication whether the parsers are JSON (True) or Regex (False)
        @param matchType:       The type of matching to use
        @param name:            The name of the dataparser
        @param requiresLogon:   Do we need to logon for this?

        @return: Nothing

        """

        data = ParserData(url)
        data.Name = name
        data.PreProcessor = preprocessor
        data.Parser = parser
        data.Creator = creator
        data.Updater = updater
        data.IsJson = json
        data.MatchType = matchType
        data.LogOnRequired = requiresLogon

        if url in self.dataParsers:
            self.dataParsers[url].append(data)
        else:
            self.dataParsers[url] = [data]
        return

    def __GetDataParsers(self, url, ):
        """ Fetches a list of dataparsers that are valid for this URL. The Parsers and Creators can then
        be used to parse the data from the url. The first match is returned.

        If none matches, the self.dataParsers dictionary is checked for generic dataparsers (marked with *).

        If no dataparsers are defined at all, they will be created based on the old regular expressions or the
        JSON queries. The regular expression suppersede the JSON.

        @param url:     The URL to match
        @return:        A list of parsers to use.

        """

        if url == "searchSite" or url == "#searchSite":
            return []

        # For now we need to be backwards compatible:
        if not self.dataParsers:
            # Add the mainlist
            if url == self.mainListUri:
                Logger.Debug("No DataParsers found. Adding old Mainlist Creators to DataParsers")
                if self.episodeItemJson is not None:
                    self._AddDataParser(self.mainListUri,
                                        parser=self.episodeItemJson, creator=self.CreateEpisodeItem,
                                        json=True, matchType=ParserData.MatchExact)

                    if self.episodeItemRegex:
                        Logger.Warning("Both JSON and Regex parsers available for mainlist, ignoring Regex.")
                else:
                    self._AddDataParser(self.mainListUri,
                                        parser=self.episodeItemRegex, creator=self.CreateEpisodeItem,
                                        matchType=ParserData.MatchExact)
            else:
                # Add the folder and video items
                Logger.Debug("No DataParsers found. Adding old FolderList Creators to DataParsers")
                self._AddDataParser("*", preprocessor=self.PreProcessFolderList)

                if self.videoItemJson is not None:
                    # foldder
                    self._AddDataParser("*", parser=self.folderItemJson, creator=self.CreateFolderItem)
                    # video
                    self._AddDataParser("*", parser=self.videoItemJson, creator=self.CreateVideoItem,
                                        updater=self.UpdateVideoItem, json=True)
                    # page
                    self._AddDataParser("*", parser=self.pageNavigationJson, creator=self.CreatePageItem,
                                        json=True)

                    if self.folderItemRegex:
                        Logger.Warning("Both JSON and Regex parsers available for folders/videos, ignoring Regex.")
                else:
                    # folder
                    self._AddDataParser("*", parser=self.folderItemRegex, creator=self.CreateFolderItem)
                    # video
                    self._AddDataParser("*", parser=self.videoItemRegex, creator=self.CreateVideoItem,
                                        updater=self.UpdateVideoItem)
                    # page
                    self._AddDataParser("*", parser=self.pageNavigationRegex, creator=self.CreatePageItem)

        # Find the parsers
        # watch = stopwatch.StopWatch('DataParsers', Logger.Instance())
        dataParsers = None
        if url.startswith("#"):
            # let's handle the keyword url's
            Logger.Trace("Found URL with labeled DataParser keyword [%s]", url)
            if url in self.dataParsers.keys():
                # use the parsers that is associated with No url (the None Parser)
                dataParsers = self.dataParsers[url]
            else:
                Logger.Warning("no DataParser was found keyword [%s]. Continuing with other options.", url)
        else:
            # make sure we sort by keylength and then start with the longest one.
            keys = sorted(self.dataParsers.keys(), key=len, reverse=True)
            # watch.Lap("DataParsers sorted")

            # filter them in order
            for key in keys:
                # for each key we see if we have filtered results
                dataParsers = filter(lambda p: p.Matches(url),
                                     self.dataParsers[key])
                if dataParsers:
                    Logger.Trace("Found %s direct DataParsers matches", len(dataParsers))
                    break
            # watch.Lap("DataParsers filtered")

        if not dataParsers:
            # Let's use a fallback
            key = "*"
            dataParsers = self.dataParsers.get(key, None)

        # watch.Lap("DataParsers processed")

        if not dataParsers:
            Logger.Error("No DataParsers found for '%s'", url)
            return []
        else:
            Logger.Debug("Found %s DataParsers for '%s'", len(dataParsers), url)
        return dataParsers

    def __str__(self):
        """Returns a string representation of the current channel."""

        if self.channelCode is None:
            return "%s [%s-%s, %s, %s, %s] (Order: %s)" % (
                self.channelName, self.id, self.version, self.language, self.category, self.guid,
                self.sortOrder)
        else:
            return "%s (%s) [%s-%s, %s, %s, %s] (Order: %s)" % (
                self.channelName, self.channelCode, self.id, self.version, self.language,
                self.category, self.guid, self.sortOrder)

    def __eq__(self, other):
        """Compares to channel objects for equality

        Arguments:
        other : Channel - the other channel to compare to

        The comparison is based only on the self.guid of the channels.

        """

        if other is None:
            return False

        return self.guid == other.guid

    def __cmp__(self, other):
        """Compares to channels

        Arguments:
        other : Channel - the other channel to compare to

        Returns:
        The return value is negative if self < other, zero if self == other and strictly positive if self > other

        """

        if other is None:
            return 1

        compVal = cmp(self.sortOrder, other.sortOrder)
        if compVal == 0:
            compVal = cmp(self.channelName, self.channelName)

        return compVal
